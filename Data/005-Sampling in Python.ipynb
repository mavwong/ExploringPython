{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1 - Introduction to Sampling\n",
    "\n",
    "- Sampling and Point Estimates\n",
    "- Convenience Sampling\n",
    "- Pseudo-Random Number Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2 - Sampling Method\n",
    "\n",
    "- Simple random and systematic sampling\n",
    "- Stratified and weighted random sampling\n",
    "- Cluster sampling\n",
    "- Comparing sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple random sampling in pandas\n",
    "df = None\n",
    "df.sample(n=5, random_state=192302)\n",
    "\n",
    "df_shuffled = df.sample(frac=1)\n",
    "df_shuffled.reset_index(drop=True, inplace=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sample size to 70\n",
    "sample_size = 70\n",
    "\n",
    "# Calculate the population size from attrition_pop\n",
    "pop_size = len(df)\n",
    "\n",
    "# Calculate the interval\n",
    "interval = pop_size // sample_size\n",
    "\n",
    "# Systematically sample 70 rows\n",
    "attrition_sys_samp = df.iloc[::interval]\n",
    "\n",
    "# Print the sample\n",
    "print(attrition_sys_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an index column to attrition_pop\n",
    "attrition_pop_id = df.reset_index()\n",
    "\n",
    "# Plot YearsAtCompany vs. index for attrition_pop_id\n",
    "attrition_pop_id.plot(x=\"index\", y=\"YearsAtCompany\", kind=\"scatter\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Shuffle the rows of attrition_pop\n",
    "attrition_shuffled = df.sample(frac=1)\n",
    "\n",
    "# Reset the row indexes and create an index column\n",
    "attrition_shuffled = attrition_shuffled.reset_index(drop=True).reset_index()\n",
    "\n",
    "# Plot YearsAtCompany vs. index for attrition_shuffled\n",
    "attrition_shuffled.plot(x=\"index\", y=\"YearsAtCompany\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot YearsAtCompany from attrition_pop as a histogram\n",
    "df_pop = None\n",
    "df_pop['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
    "plt.show()\n",
    "\n",
    "# Sample 400 employees weighted by YearsAtCompany\n",
    "attrition_weight = df_pop.sample(\n",
    "    n=400, \n",
    "    weights=\"YearsAtCompany\"\n",
    ")\n",
    "\n",
    "# Plot YearsAtCompany from attrition_weight as a histogram\n",
    "attrition_weight['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLUSTER SAMPLING\n",
    "import random\n",
    "\n",
    "df_pop = None\n",
    "\n",
    "# Create a list of unique JobRole values\n",
    "job_roles_pop = list(df_pop['JobRole'].unique())\n",
    "\n",
    "# Randomly sample four JobRole values\n",
    "job_roles_samp = random.sample(job_roles_pop, k=4)\n",
    "\n",
    "# Filter for rows where JobRole is in job_roles_samp\n",
    "jobrole_condition = df_pop['JobRole'].isin(job_roles_samp)\n",
    "attrition_filtered = df_pop[jobrole_condition]\n",
    "\n",
    "# Remove categories with no rows\n",
    "attrition_filtered['JobRole'] = attrition_filtered['JobRole'].cat.remove_unused_categories()\n",
    "\n",
    "# Randomly sample 10 employees from each sampled job role\n",
    "attrition_clust = attrition_filtered.groupby(\"JobRole\")\\\n",
    "    .sample(n=10, random_state=2022)\n",
    "\n",
    "# Print the sample\n",
    "print(attrition_clust)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform simple random sampling to get 0.25 of the population\n",
    "attrition_srs = df_pop.sample(frac=0.25, random_state=2022)\n",
    "\n",
    "# Perform stratified sampling to get 0.25 of each relationship group\n",
    "attrition_strat = df_pop.groupby(\"RelationshipSatisfaction\")\\\n",
    "    .sample(frac=0.25, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 KINDS OF SAMPLING\n",
    "# Create a list of unique RelationshipSatisfaction values\n",
    "satisfaction_unique = list(df_pop['RelationshipSatisfaction'].unique())\n",
    "\n",
    "# Randomly sample 2 unique satisfaction values\n",
    "satisfaction_samp = random.sample(satisfaction_unique, k=2)\n",
    "\n",
    "# Filter for satisfaction_samp and clear unused categories from RelationshipSatisfaction\n",
    "satis_condition = df_pop['RelationshipSatisfaction'].isin(satisfaction_samp)\n",
    "attrition_clust_prep = df_pop[satis_condition]\n",
    "attrition_clust_prep['RelationshipSatisfaction'] = attrition_clust_prep['RelationshipSatisfaction'].cat.remove_unused_categories()\n",
    "\n",
    "# Perform cluster sampling on the selected group, getting 0.25 of attrition_pop\n",
    "attrition_clust = attrition_clust_prep.groupby(\"RelationshipSatisfaction\")\\\n",
    "    .sample(n=len(df_pop) // 4, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing point estimates (simple, stratified, cluster)\n",
    "\n",
    "# Mean Attrition by RelationshipSatisfaction group\n",
    "mean_attrition_pop = df_pop.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(mean_attrition_pop)\n",
    "\n",
    "\n",
    "# Calculate the same thing for the simple random sample \n",
    "mean_attrition_srs = attrition_srs.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(mean_attrition_srs)\n",
    "\n",
    "\n",
    "# Calculate the same thing for the stratified sample \n",
    "mean_attrition_strat = attrition_strat.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(mean_attrition_strat)\n",
    "\n",
    "\n",
    "# Calculate the same thing for the cluster sample \n",
    "mean_attrition_clust = attrition_clust.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(mean_attrition_clust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3 - Sampling Distributions\n",
    "\n",
    "- Relative error of point estimates\n",
    "- Creating a sampling distribution\n",
    "- Approximate sampling distribution\n",
    "- Standard errors and the central limit theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a simple random sample of 100 rows, with seed 2022\n",
    "attrition_srs100 = df_pop.sample(n=100, random_state=2022)\n",
    "\n",
    "# Calculate the mean employee attrition in the sample\n",
    "mean_attrition_srs100 = attrition_srs100['Attrition'].mean()\n",
    "\n",
    "# Calculate the relative error percentage\n",
    "rel_error_pct100 = 100 * abs(mean_attrition_pop - mean_attrition_srs100) / mean_attrition_pop\n",
    "\n",
    "# Print rel_error_pct100\n",
    "print(rel_error_pct100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list\n",
    "mean_attritions = []\n",
    "# Loop 500 times to create 500 sample means\n",
    "for i in range(500):\n",
    "\tmean_attritions.append(\n",
    "    \tattrition_pop.sample(n=60)['Attrition'].mean()\n",
    "\t)\n",
    "\n",
    "# Create a histogram of the 500 sample means\n",
    "plt.hist(mean_attritions, bins=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### APROXIMATE SAMPLING DISTRIBUTION\n",
    "\n",
    "# Expand a grid representing 5 8-sided dice\n",
    "dice = expand_grid(\n",
    "  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die2': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die3': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die4': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die5': [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  })\n",
    "\n",
    "# Add a column of mean rolls and convert to a categorical\n",
    "dice['mean_roll'] = (dice['die1'] + dice['die2'] + \n",
    "                     dice['die3'] + dice['die4'] + \n",
    "                     dice['die5']) / 5\n",
    "dice['mean_roll'] = dice['mean_roll'].astype('category')\n",
    "\n",
    "# Draw a bar plot of mean_roll\n",
    "dice['mean_roll'].value_counts(sort=False).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### APROXIMATE SAMPLING DISTRIBUTION\n",
    "\n",
    "# Replicate the sampling code 1000 times\n",
    "sample_means_1000 = []\n",
    "for i in range(1000):\n",
    "    sample_means_1000.append(\n",
    "  \t\tnp.random.choice(list(range(1, 9)), size=5, replace=True).mean()\n",
    "    )\n",
    "\n",
    "# Draw a histogram of sample_means_1000 with 20 bins\n",
    "plt.hist(sample_means_1000, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD ERRORS AND THE CENTRAL LIMIT THEOREM\n",
    "\n",
    "# Calculate the mean of the mean attritions for each sampling distribution\n",
    "mean_of_means_5 = np.mean(sampling_distribution_5)\n",
    "mean_of_means_50 = np.mean(sampling_distribution_50)\n",
    "mean_of_means_500 = np.mean(sampling_distribution_500)\n",
    "\n",
    "# Print the results\n",
    "print(mean_of_means_5)\n",
    "print(mean_of_means_50)\n",
    "print(mean_of_means_500)\n",
    "\n",
    "\n",
    "# Calculate the std. dev. of the mean attritions for each sampling distribution\n",
    "sd_of_means_5 = np.std(sampling_distribution_5, ddof=1)\n",
    "sd_of_means_50 = np.std(sampling_distribution_50, ddof=1)\n",
    "sd_of_means_500 = np.std(sampling_distribution_500, ddof=1)\n",
    "\n",
    "# Print the results\n",
    "print(sd_of_means_5)\n",
    "print(sd_of_means_50)\n",
    "print(sd_of_means_500)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4\n",
    "\n",
    "- Introduction to Bootstrapping\n",
    "- Comparing sampling and bootstrap distributions\n",
    "- Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_popularity_2000_samp = []\n",
    "\n",
    "# Generate a sampling distribution of 2000 replicates\n",
    "for i in range(2000):\n",
    "    mean_popularity_2000_samp.append(\n",
    "    \t# Sample 500 rows and calculate the mean popularity     \n",
    "    \tspotify_population.sample(n=500)['popularity'].mean()\n",
    "    )\n",
    "\n",
    "# Print the sampling distribution results\n",
    "print(mean_popularity_2000_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_popularity_2000_boot = []\n",
    "\n",
    "# Generate a bootstrap distribution of 2000 replicates\n",
    "for i in range(2000):\n",
    "    mean_popularity_2000_boot.append(\n",
    "    \t# Resample 500 rows and calculate the mean popularity\n",
    "    \tspotify_sample.sample(n=500, replace=True)['popularity'].mean()\n",
    "    )\n",
    "\n",
    "# Print the bootstrap distribution results\n",
    "print(mean_popularity_2000_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the population mean popularity\n",
    "pop_mean = spotify_population['popularity'].mean()\n",
    "\n",
    "# Calculate the original sample mean popularity\n",
    "samp_mean = spotify_sample['popularity'].mean()\n",
    "\n",
    "# Calculate the sampling dist'n estimate of mean popularity\n",
    "samp_distn_mean = np.mean(sampling_distribution)\n",
    "\n",
    "# Calculate the bootstrap dist'n estimate of mean popularity\n",
    "boot_distn_mean = np.mean(bootstrap_distribution)\n",
    "\n",
    "# Print the means\n",
    "print([pop_mean, samp_mean, samp_distn_mean, boot_distn_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the population std dev popularity\n",
    "pop_sd = spotify_population['popularity'].std(ddof=0)\n",
    "\n",
    "# Calculate the original sample std dev popularity\n",
    "samp_sd = spotify_sample['popularity'].std()\n",
    "\n",
    "# Calculate the sampling dist'n estimate of std dev popularity\n",
    "samp_distn_sd = np.std(sampling_distribution, ddof=1) * np.sqrt(5000)\n",
    "\n",
    "# Calculate the bootstrap dist'n estimate of std dev popularity\n",
    "boot_distn_sd = np.std(bootstrap_distribution, ddof=1) * np.sqrt(5000)\n",
    "\n",
    "# Print the standard deviations\n",
    "print([pop_sd, samp_sd, samp_distn_sd, boot_distn_sd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIDENCE INTERVALS\n",
    "\n",
    "\n",
    "# Generate a 95% confidence interval using the quantile method\n",
    "lower_quant = np.quantile(bootstrap_distribution, 0.025)\n",
    "upper_quant = np.quantile(bootstrap_distribution, 0.975)\n",
    "\n",
    "# Print quantile method confidence interval\n",
    "print((lower_quant, upper_quant))\n",
    "\n",
    "\n",
    "# Find the mean and std dev of the bootstrap distribution\n",
    "point_estimate = np.mean(bootstrap_distribution)\n",
    "standard_error = np.std(bootstrap_distribution, ddof=1)\n",
    "\n",
    "# Find the lower limit of the confidence interval\n",
    "lower_se = norm.ppf(0.025, loc=point_estimate, scale=standard_error)\n",
    "\n",
    "# Find the upper limit of the confidence interval\n",
    "upper_se = norm.ppf(0.975, loc=point_estimate, scale=standard_error)\n",
    "\n",
    "# Print standard error method confidence interval\n",
    "print((lower_se, upper_se))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
