{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Types of Statistics\n",
    "- Descriptive Statistics - describe and summarizes the data\n",
    "- Inferential Statistics -  use of data to make inferences about a larger population\n",
    "\n",
    "Types of Data\n",
    "- Numeric (Quantitative)\n",
    "    - Continuous: Measured - Airplane, Time Spent\n",
    "    - Discrete: Counted - Number of Pets, Number of Packages Shipped\n",
    "\n",
    "- Categorical (Qualitative)\n",
    "    - Nominal: Unordered\n",
    "    - Ordinal: Ordered\n",
    "    \n",
    "    \n",
    "Continuous vs Discrete vs Categorical\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "The field of statistics - the practice or study of collecting and analyzing data\n",
    "Summary Statistics - a fact about or summary of some data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy with alias np\n",
    "import numpy as np\n",
    "\n",
    "food_consumption = None\n",
    "\n",
    "# Filter for Belgium\n",
    "be_consumption = food_consumption[food_consumption['country'] == 'Belgium']\n",
    "\n",
    "# Filter for USA\n",
    "usa_consumption = food_consumption[food_consumption['country'] == 'USA']\n",
    "\n",
    "# Calculate mean and median consumption in Belgium\n",
    "print(np.mean(be_consumption['consumption']))\n",
    "print(np.median(be_consumption['consumption']))\n",
    "\n",
    "# Calculate mean and median consumption in USA\n",
    "print(np.mean(usa_consumption['consumption']))\n",
    "print(np.median(usa_consumption['consumption']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# Subset for Belgium and USA only\n",
    "be_and_usa = food_consumption[(food_consumption['country'] == 'Belgium') | (food_consumption['country'] == 'USA')]\n",
    "\n",
    "# Group by country, select consumption column, and compute mean and median\n",
    "print(be_and_usa.groupby(\"country\")[\"consumption\"].agg([np.mean, np.median]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the Spread of the data\n",
    "# - Standard Deviation: np.std(df[\"columns\"], ddof=1)\n",
    "# - Variance: np.var(df[\"columns\"], ddof=1)\n",
    "# - Mean Absolute Deviation\n",
    "\n",
    "# standard deviation squares distances, penalizing longer distances more than shorter ones.\n",
    "# Standard Deviation is more common other than Mean Absolute Deviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantiles\n",
    "# Interquartile Range (IQR)\n",
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "# Quantiles\n",
    "np.quantile(df[\"columns\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of Spread (Location based within the data)\n",
    "\n",
    "Measures how apart or close together the data points are.\n",
    "- Variance\n",
    "- Standard Deviation\n",
    "- Mean Absolute Deviation\n",
    "\n",
    "- Quantiles | Percentiles\n",
    "- Interquartile Range (IQR)\n",
    "- Outliers\n",
    "\n",
    "Note\n",
    "- Standard Deviation is more common than Mean Absolute Deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance on a sample population\n",
    "np.var(df[\"columns\"], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation\n",
    "np.std(df[\"columns\"], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Deviation\n",
    "# dists = msleep[\"sleep_total\"] - mean(msleep$sleep_total)\n",
    "# np.mean(np.abs(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantiles\n",
    "np.quantile(df[\"column\"], 0.5)  # Same as the median\n",
    "np.quantile(df[\"column\"], [0,0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interquartile Range\n",
    "np.quantile(df[\"column\"], 0.75) - np.quantile(df[\"column\"], 0.25)\n",
    "\n",
    "from scipy.stats import iqr\n",
    "iqr(df[\"column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers - data point that is substantially different from the others\n",
    "# Formula\n",
    "# data < Q1 - 1.5 x IQR or data > Q3 + 1.5 x IQR\n",
    "\n",
    "# Process\n",
    "# - calculate the IQR\n",
    "# - calculate the lower threshold\n",
    "# - calculate the upper threshold\n",
    "# - subset or slice the dataframe to get the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR\n",
    "from scipy.stats import iqr\n",
    "iqr = iqr(df[\"columns\"])\n",
    "\n",
    "# Calculate the upper and lower threshold\n",
    "lower_threshold = np.quantile(df[\"columns\"], 0.25) - 1.5 * iqr\n",
    "upper_threshold = np.quantile(df[\"columns\"], 0.75) + 1.5 * iqr\n",
    "\n",
    "# Subset the data (Slicing the data)\n",
    "df[(df[\"columns\"]<lower_threshold) | (df[\"columns\"]>upper_threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating everything\n",
    "df[\"columns\"].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "# Print variance and sd of co2_emission for each food_category\n",
    "print(food_consumption.groupby('food_category')['co2_emission'].agg([np.var, np.std]))\n",
    "\n",
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'beef'\n",
    "food_consumption[food_consumption['food_category'] == 'beef']['co2_emission'].hist()\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'eggs'\n",
    "food_consumption[food_consumption['food_category'] == 'eggs']['co2_emission'].hist()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2: Random Numbers and Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With or Without Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the deals for each product\n",
    "product_count = df[\"product\"].value_count()\n",
    "\n",
    "# Calculate the probability of picking a deal with each product\n",
    "product_probability = product_count / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "np.random.seed(24)\n",
    "\n",
    "# Sample 5 deals without replacement\n",
    "sample = df.sample(5)\n",
    "\n",
    "# Sample 5 deals with replacement\n",
    "sample = df.sample(5, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discrete Distribution - Video\n",
    "1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from Discrete Distribution\n",
    "die = None\n",
    "rolls_10 = None\n",
    "\n",
    "die.sample(10, replace=True)\n",
    "\n",
    "# Visualizing the die sample\n",
    "rolls_10[\"number\"].hist(bins=np.linspace(1,7,7))\n",
    "\n",
    "# Law of Large Number - as the size of your sample increases, the sample\\\n",
    "    # mean will approach the expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from Discrete Distribution\n",
    "\n",
    "# # Create probability distribution\n",
    "# size_dist = restaurant_groups['group_size'].value_counts() / restaurant_groups.shape[0]\n",
    "\n",
    "# # Reset index and rename columns\n",
    "# size_dist = size_dist.reset_index()\n",
    "# size_dist.columns = ['group_size', 'prob']\n",
    "\n",
    "# # Expected value\n",
    "# expected_value = np.sum(size_dist['group_size'] * size_dist['prob'])\n",
    "\n",
    "# # Subset groups of size 4 or more\n",
    "# groups_4_or_more = size_dist[size_dist['group_size'] >= 4]\n",
    "\n",
    "# # Sum the probabilities of groups_4_or_more\n",
    "# prob_4_or_more = np.sum(groups_4_or_more['prob'])\n",
    "# print(prob_4_or_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from Continuous Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Types of distribution.\n",
    "- Discrete\n",
    "- Continuous\n",
    "- Binomial \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Distributions\n",
    "# Outcome based on two values\n",
    "# - True or False\n",
    "# - Pass or Fail \n",
    "# - Head or Tail\n",
    "\n",
    "# Probability distribution of the number of successes in a sequence of independent trials.\n",
    "\n",
    "# Number of heads in a sequence of coin flips\n",
    "# - n: total number of trials\n",
    "# - p: probability of success\n",
    "\n",
    "\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flip 1 coin with 50% chance of success 8 times. \n",
    "binom.rvs(1, 0.5, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip 8 coins with 50% chance of success 1 time\n",
    "binom.rvs(8, 0.5, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip 3 coins with 50% chance of success 10 times\n",
    "\n",
    "# Flip 3 coins with 25% chance of success 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11718750000000014"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of 7 heads - Getting more probability of 7 heads\n",
    "# binom.pmf(num_heads, num_trials, prob_of_heads)\n",
    "binom.pmf(7,10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of 7 or fewer heads\n",
    "# p(heads<=7)\n",
    "binom.cdf(1,3,0.3)\n",
    "\n",
    "# Probability of closing > 1 deal out of 3 deals\n",
    "1 - binom.cdf(1,3,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution or the Bell Curve.\n",
    "68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Cumulative distribution function\n",
    "# What percent of women are shorter than 154?\n",
    "norm.cdf(154, 161, 7)\n",
    "\n",
    "# What percent of women are taller than 154?\n",
    "\n",
    "\n",
    "# What percent of women are 154 to 157 cm?\n",
    "norm.cdf(157, 161, 7) - \\\n",
    "    norm.cdf(154, 161, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What height are 90% of the women shorter than?\n",
    "norm.ppf(0.90, 161, 7)\n",
    "\n",
    "# What height are 90% of the women taller than?\n",
    "norm.ppf((1-0.90), 161, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random numbers\n",
    "norm.rvs(161, 7, size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
